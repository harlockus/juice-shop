name: Veracode Ultimate (Pipeline Scan + SARIF + Batch Fix)

on:
  workflow_dispatch:
    inputs:
      run_fix:
        description: "Run Veracode Fix (batch PR) after scan"
        required: true
        default: "true"
  pull_request:
    branches: [ main, master ]

permissions:
  contents: write
  pull-requests: write
  actions: read
  security-events: write

jobs:
  pipeline_scan_and_sarif:
    if: github.event_name != 'pull_request' || !startsWith(github.head_ref, 'veracode-single-fix-holder-')
    runs-on: ubuntu-latest
    outputs:
      has_results: ${{ steps.scan_outputs.outputs.has_results }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure placeholder file exists (SARIF)
        run: |
          mkdir -p .veracode
          cat > .veracode/PIPELINE_SCAN_GLOBAL_FINDINGS.md << 'EOF'
          # Veracode Pipeline Scan – Global Findings Placeholder
          Findings without a resolvable repo file+line are anchored here.
          EOF

      - name: Create source zip (exclude node_modules)
        run: |
          zip -r pipeline-src.zip . -x "**/node_modules/**" -x "**/.git/**"

      - name: Set up Java (Pipeline Scan tool)
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17"

      - name: Download Pipeline Scan tool
        run: |
          curl -sSLO https://downloads.veracode.com/securityscan/pipeline-scan-LATEST.zip
          unzip -o pipeline-scan-LATEST.zip

      - name: Run Pipeline Scan (ESD enabled, do not fail job on findings)
        id: scan_outputs
        env:
          VERACODE_API_ID: ${{ secrets.VERACODE_API_ID }}
          VERACODE_API_KEY: ${{ secrets.VERACODE_API_KEY }}
        run: |
          set -euo pipefail

          set +e
          java -jar pipeline-scan.jar \
            -vid "${VERACODE_API_ID}" \
            -vkey "${VERACODE_API_KEY}" \
            -f "pipeline-src.zip" \
            -esd true \
            -jf "results.json" \
            -fjf "filtered_results.json"
          RC=$?
          set -e

          echo "Pipeline Scan exit code: $RC"
          ls -lah results.json filtered_results.json || true

          if [ -f results.json ] && [ -f filtered_results.json ]; then
            echo "has_results=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_results=false" >> "$GITHUB_OUTPUT"
            echo "ERROR: Pipeline Scan did not produce results.json / filtered_results.json"
            exit 1
          fi

      - name: Setup Python (SARIF conversion)
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Convert Pipeline JSON -> SARIF
        run: |
          python scripts/pipeline_results_to_sarif.py \
            --input filtered_results.json \
            --output veracode-pipeline.sarif \
            --placeholder-uri .veracode/PIPELINE_SCAN_GLOBAL_FINDINGS.md \
            --output-stats veracode-pipeline-sarif-stats.json

      - name: Upload SARIF to GitHub Code Scanning
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: veracode-pipeline.sarif
          category: veracode-pipeline
          wait-for-processing: true

      - name: Upload pipeline artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: veracode-pipeline-scan
          path: |
            results.json
            filtered_results.json
            veracode-pipeline.sarif
            veracode-pipeline-sarif-stats.json
            .veracode/PIPELINE_SCAN_GLOBAL_FINDINGS.md

  build_fix_matrix:
    needs: pipeline_scan_and_sarif
    if: needs.pipeline_scan_and_sarif.outputs.has_results == 'true'
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.mk.outputs.matrix }}

    steps:
      - name: Download scan outputs
        uses: actions/download-artifact@v4
        with:
          name: veracode-pipeline-scan
          path: pipeline_out

      - name: Setup Python (matrix builder)
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Build Fix matrix dynamically from findings (only batch-fixable)
        id: mk
        run: |
          python - << 'PY'
          import json, os
          from collections import Counter

          # Batch-fix CWE allow lists (batch-supported by language)
          ALLOW = {
            "java":       {"80","89","113","117","159","209","331","404","597","611"},
            "kotlin":     {"80","89","113","117","331","404"},
            "scala":      {"78","80","117","611"},
            "csharp":     {"80","89","117","209","316","331","352","404","611"},
            "javascript": {"80","89","113","117","209","352","601","611","614"},
            "python":     {"78","80","89","295","331","757"},
            "php":        {"80","89","117"},
            "go":         {"73","78","117"},
          }

          EXT_TO_LANG = {
            ".java":"java", ".jsp":"java",
            ".kt":"kotlin",
            ".scala":"scala",
            ".cs":"csharp",
            ".js":"javascript", ".ts":"javascript", ".jsx":"javascript", ".tsx":"javascript",
            ".py":"python",
            ".php":"php",
            ".go":"go",
          }

          def norm(p: str) -> str:
            return (p or "").replace("\\","/").strip()

          def src_path(f: dict) -> str:
            src = ((f.get("files") or {}).get("source_file") or {})
            return norm(src.get("file") or src.get("upload_file") or "")

          data = json.load(open("pipeline_out/filtered_results.json","r",encoding="utf-8"))
          findings = data.get("findings", []) if isinstance(data, dict) else []

          # Determine which languages have at least one batch-fixable CWE in the findings
          lang_has_fixable = {k: False for k in ALLOW.keys()}

          # For better JS path mapping: count top-level dirs among JS findings
          js_root_counts = Counter()

          for f in findings:
            if not isinstance(f, dict):
              continue
            p = src_path(f).lower()
            lang = None
            for ext, l in EXT_TO_LANG.items():
              if p.endswith(ext):
                lang = l
                break
            if not lang:
              continue
            cwe = str(f.get("cwe_id") or "").strip()
            if cwe and cwe in ALLOW.get(lang, set()):
              lang_has_fixable[lang] = True

            if lang == "javascript":
              parts = p.split("/")
              if parts and parts[0]:
                js_root_counts[parts[0]] += 1

          def pick_js_root():
            # Prefer common roots if present, else most common top-level folder
            preferred = ["src","routes","frontend","lib","app","server","client","packages"]
            for d in preferred:
              if js_root_counts.get(d, 0) > 0 and os.path.isdir(d):
                return d
            if js_root_counts:
              top = js_root_counts.most_common(1)[0][0]
              return top if os.path.isdir(top) else "src"
            return "src"

          js_root = pick_js_root()

          BASE = {
            "java":       ("com/:src/main/java/com/","WEB-INF:src/main/webapp/WEB-INF",""),
            "kotlin":     ("com/:src/main/java/com/","",""),
            "scala":      ("com/:src/main/java/com/","",""),
            "csharp":     ("src/:src/","",""),
            "javascript": (f"{js_root}/:{js_root}/","",""),
            "python":     ("src/:src/","app/:app/",""),
            "php":        ("src/:src/","",""),
            "go":         ("src/:src/","",""),
          }

          include = []
          for lang, ok in lang_has_fixable.items():
            if not ok:
              continue
            sbp1, sbp2, sbp3 = BASE[lang]
            cwe_list = ",".join(sorted(ALLOW[lang], key=lambda x: int(x)))
            include.append({"language": lang, "cwe": cwe_list, "sbp1": sbp1, "sbp2": sbp2, "sbp3": sbp3})

          matrix = {"include": include}
          matrix_str = json.dumps(matrix, separators=(",", ":"))

          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as out:
            out.write(f"matrix={matrix_str}\n")

          print("Batch-fix languages to run:", [x["language"] for x in include])
          PY

  veracode_fix_universal:
    needs: [pipeline_scan_and_sarif, build_fix_matrix]
    if: (github.event_name == 'pull_request' || inputs.run_fix == 'true') && needs.build_fix_matrix.outputs.matrix != '' && needs.build_fix_matrix.outputs.matrix != '{"include":[]}'
    runs-on: ubuntu-latest
    timeout-minutes: 120
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix: ${{ fromJson(needs.build_fix_matrix.outputs.matrix) }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download scan outputs
        uses: actions/download-artifact@v4
        with:
          name: veracode-pipeline-scan
          path: pipeline_out

      - name: Setup Python (Fix input filtering)
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Filter Fix input to language=${{ matrix.language }} and allowed CWEs only
        id: filter
        run: |
          set -euo pipefail
          python - << 'PY'
          import json, os

          lang = os.environ["LANG"]
          allow = set(os.environ["ALLOW_CWES"].split(",")) if os.environ.get("ALLOW_CWES") else set()
          inp = "pipeline_out/filtered_results.json"
          outp = f"pipeline_out/filtered_results_{lang}.json"

          LANG_EXTS = {
            "java": [".java", ".jsp"],
            "kotlin": [".kt"],
            "scala": [".scala"],
            "csharp": [".cs"],
            "javascript": [".js", ".ts", ".jsx", ".tsx"],
            "python": [".py"],
            "php": [".php"],
            "go": [".go"],
          }

          exts = LANG_EXTS.get(lang, [])
          if not exts:
            raise SystemExit(f"No ext mapping for {lang}")

          def norm(p): return (p or "").replace("\\","/").strip()
          def src_path(f):
            src = ((f.get("files") or {}).get("source_file") or {})
            return norm(src.get("file") or src.get("upload_file") or "")

          data = json.load(open(inp, "r", encoding="utf-8"))
          findings = data.get("findings", []) if isinstance(data, dict) else []

          kept = []
          for f in findings:
            if not isinstance(f, dict):
              continue
            p = src_path(f).lower()
            if not any(p.endswith(e) for e in exts):
              continue
            cwe = str(f.get("cwe_id") or "").strip()
            if allow and cwe not in allow:
              continue
            kept.append(f)

          data2 = dict(data)
          data2["findings"] = kept
          json.dump(data2, open(outp, "w", encoding="utf-8"), indent=2)

          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as g:
            g.write(f"count={len(kept)}\n")
            g.write(f"file={outp}\n")

          print(f"Filtered for {lang} (allowed CWEs only): {len(kept)}")
          PY
        env:
          LANG: ${{ matrix.language }}
          ALLOW_CWES: ${{ matrix.cwe }}

      - name: Skip Fix when no batch-fixable findings for this language
        if: steps.filter.outputs.count == '0'
        run: |
          echo "No batch-fixable findings for language=${{ matrix.language }}. Skipping Fix."

      - name: Run Veracode Fix (Batch → PR) — language=${{ matrix.language }}
        if: steps.filter.outputs.count != '0'
        continue-on-error: true
        uses: Veracode/veracode-fix@v1.0.4
        with:
          vid: ${{ secrets.VID }}
          vkey: ${{ secrets.VKEY }}
          inputFile: ${{ steps.filter.outputs.file }}
          language: ${{ matrix.language }}
          cwe: ${{ matrix.cwe }}
          fixType: batch
          files: all
          prComment: true
          createPR: true
          source_base_path_1: ${{ matrix.sbp1 }}
          source_base_path_2: ${{ matrix.sbp2 }}
          source_base_path_3: ${{ matrix.sbp3 }}
